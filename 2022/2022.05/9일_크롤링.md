## 구상

크롤링을 시작하기 전에, 한번 구상을 해봐야합니다. 제 페이지에서 만들어놓은 종목들이 많기때문에, 종목을 클릭하면 그 종목에 맞는 크롤링된 뉴스들이 보여져야 합니다. 다만... 그렇다면 종목마다 html 페이지를 따로 만들어야 하나요?

- 복붙이야 얼마 걸리지 않기때문에 괜찮지만.. html페이지가 많아지는건 그닥 반가운 소식은 아닌 것 같아서요.

- if문이나 `addEventListener`를 활용하면 하나의 html로 모든 종목의 웹크롤링이 가능하겠지만, url에 어떤 종목인지 표시하고싶은 욕심을 포기해야합니다.

  - 자바스크립트로 url만 바꾸는 함수가 존재하긴 하지만, 그냥 눈에 보이는 거로만 바뀌는 작업이다 보니 여러가지 한계점이 존재했습니다.

  - 제가 원하는 작업을 하려면 백엔드(Express)를 간단하게라도 구현하거나, React를 사용해야 하는 것 같습니다.

  - 일단은 자바스크립트로 저의 수준에 맞게 만들 수 있는 부분까지 만들고, 나중에 React를 배우고나면 유지보수를 진행하는 방안으로 가도록 하겠습니다.

---

## promise, async, await

![](https://velog.velcdn.com/images/duckgus/post/e37b6e84-2577-4032-b431-2a34edc9818d/image.png)

일단 제가 필요한 부분을 한번 찾아보겠습니다.

body > div(id="wrap") > div(id="container") > div(id="content") > div(id="main_pack") > div(class="api_subject_bx") > div(class="group_news") > ul(class="list_news") > li(class="bx")

정말 많은 요소들을 거쳐 내려왔습니다.

제가 참고하고있는 블로그에 소스코드를 올려주셨는데,

```js
const axios = require("axios");
const cheerio = require("cheerio");

async function getHTML() {
  try {
    return await axios.get(
      "https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90"
    );
  } catch (error) {
    console.error(error);
  }
}
```

- 여기서 걸리는 부분. `async`, `await`, 그리고 검색해보니 `Promise`까지와도 연결되어있는 이 세 가지 문법입니다. 밑의 블로그를 보고 이 세 가지 문법에 대해 이해하려 노력하였습니다.

[[Javascript] 비동기, Promise, async, await 확실하게 이해하기](https://elvanov.com/2597)

웹크롤링 시작 이틀째인데, 후회가됩니다. 너무 어려워! 반은 이해되고 반은 이해되지 않은 느낌입니다. 그래도 열심히 해야죠, 꾸준히.

- 그러니까 여기서 배운걸 바탕으로 위의 코드를 한번 해석해보자면,

  - `async`를 활용하여 `getHTML`이라는 비동기 함수를 만들었습니다.

  - 이 함수는 axios를 활용하여 html의 정보를 받아옵니다. `await`을 활용하여 이 작업이 완료될 때 까지 다른 코드의 실행을 멈추고 기다립니다. (html의 정보를 다 받아와야 가공할 수 있으므로)

  - 정도로 이해가 됩니다. 그렇다면 이 밑에 있는 코드는 axios에서 받아온 데이터를 cheerio를 활용하여 가공하는 과정이 되겠군요.

---

## 예상되는 문제점

블로그에 있는 소스코드를 그대로 사용할 경우 예상되는 문제점이 있습니다. 저는 받아와야 할 url이 다양하다는 점입니다. 게다가 한글로 되어있어 인코딩 작업또한 필요합니다.

```js
import axios from "axios";
import cheerio from "cheerio";

let searchKeyWord = encodeURI("삼성전자");
// axios를 활용해 AJAX로 HTML 문서를 가져오는 함수 구현
async function getHTML() {
  try {
    return await axios.get(
      `https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=${searchKeyWord}`
    );
  } catch (error) {
    console.error(error);
  }
}
```

따라서 `searchKeyWord`라는 변수를 하나 선언해주었습니다. 검색어가 무엇이냐에 따라 언제든지 수정이 가능해야 하므로 let으로 선언해주었습니다.

- 이제 밑부분을 이해해보도록 합시다. html을 받아와서, 거기서 필요한 요소를 배열로 저장하는 듯 보입니다. 저장해야 할 요소는 html 구성요소에 따라 달라지므로, 제가 찾고자 하는 웹페이지에 맞게 변경을 해주어야 합니다.

  - 일단 제가 찾고자 하는 웹페이지의 요소에 맞추어 변경을 하고,

  - 제대로 작동하는지 확인한 후,

  - 안도감과 함께 코드를 이해해보는 시간을 갖도록 하겠습니다.

## 예상치 못한 문제점

```js
getHTML()
  .then((html) => {
    let titleList = [];
    const $ = cheerio.load(html.data);
    // ul.list_news를 찾고 그 children 노드를 bodyList에 저장
    const bodyList = $("ul.list_news").children("li.bx");

    // bodyList를 순회하며 titleList에 div > div > a의 내용을 저장
    bodyList.each(function (i, elem) {
      titleList[i] = {
        title: $(this).find("div div a").text(),
      };
    });
    return titleList;
  })
  .then((res) => console.log(res));
```

밑부분에 해당하는 코드입니다. 여기서 실행해보니 콘솔에 정상적으로 웹 크롤링이 진행되고 있는것이 보입니다... 만. 문제점이 생겼습니다.

콘솔창에 출력된 결과 중 하나만을 가져와보겠습니다.

> {

    title: `문서 저장하기Keep에 저장Keep 바로가기뉴시스언론사 선정네이버뉴스삼성 "6G 시대, 소외 없이 누구나 '초실감' 경험 누릴 것"삼성전자 DX(Device eXperience) 부문의 선행 기술 연구 중 6G 기술 연구를 이끄는 최 부사장은 이날 삼성전자 뉴스룸과의 인터뷰를 통해 "6G는 우리의 삶 곳곳, 그리고 다양한 산업군에 큰 변화를 일으킬 차세대 이동통신...`

},

이렇게 출력되었는데, 뭔가 이상한 점을 눈치채셨나요?

제가 확인했을 땐 div > div > a로 들어가면 그 a가 제목에 해당하길래, 제목만을 가져올 줄 알았습니다.

- 그러나 떡하니 적혀있는 문서 저장하기, Keep에 저장, Keep바로가기, 등등등 버튼으로 만들어져있을법한 글씨들...

- 확인해보니 div > div > div > a 에 있는 a까지 싹 다 긁어와 저에게 크롤링했더군요. a의 범위를 조금 더 특정할 필요가 있습니다.

- 일단 이 문제를 어떻게 해결할지는 다른 일정을 소화한 후에 고민해보도록 하겠습니다. 대학교 강의도 들어야 하고, 운동도 해야하고, 오늘은 저녁약속까지 있군요.
